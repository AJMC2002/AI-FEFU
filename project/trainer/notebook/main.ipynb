{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a469ca34",
   "metadata": {},
   "source": [
    "# Project: Chinese Chess cDNN Model\n",
    "First install dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b54e7195",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 00:47:43.766917: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1738075663.996674   58867 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1738075664.061168   58867 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-29 00:47:44.550373: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as tfk\n",
    "from bidict import bidict\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "tfk.mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices(\"GPU\")))\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "DATA_PATH = \"../data/MOVES.DAT\"\n",
    "BOARD_SIZE = (10, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842ac70f",
   "metadata": {},
   "source": [
    "Now we creat bidirectional dictionaries in order to encode and decode the pieces and moves.\n",
    "#\n",
    "PIECE_VAL encodes the pieces to some int.\n",
    "#\n",
    "MOVE_ID encodes the best move from FEN format to an int."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0f91835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bidict({'K': 1, 'A': 2, 'B': 3, 'N': 4, 'R': 5, 'C': 6, 'P': 7, 'k': 8, 'a': 9, 'b': 10, 'n': 11, 'r': 12, 'c': 13, 'p': 14})\n"
     ]
    }
   ],
   "source": [
    "PIECE_VAL = bidict(\n",
    "    {\n",
    "        \"K\": 1,  # Red King\n",
    "        \"A\": 2,  # Red Advisor\n",
    "        \"B\": 3,  # Red Elephant\n",
    "        \"N\": 4,  # Red Horse\n",
    "        \"R\": 5,  # Red Chariot\n",
    "        \"C\": 6,  # Red Cannon\n",
    "        \"P\": 7,  # Red Pawn\n",
    "        \"k\": 8,  # Black King\n",
    "        \"a\": 9,  # Black Advisor\n",
    "        \"b\": 10,  # Black Elephant\n",
    "        \"n\": 11,  # Black Horse\n",
    "        \"r\": 12,  # Black Chariot\n",
    "        \"c\": 13,  # Black Cannon\n",
    "        \"p\": 14,  # Black Pawn\n",
    "    }\n",
    ")\n",
    "\n",
    "print(PIECE_VAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdcfce52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bidict({'g3e3': 0, 'e4f4': 1, 'e3e1': 2, 'g2g3': 3, 'e2i2': 4, 'b5g5': 5, 'e2e9': 6, 'g0c0': 7, 'i7h5': 8, 'd1a1': 9, 'h3h5': 10, 'd1d3': 11, 'e2g4': 12, 'i3f3': 13, 'c5d5': 14, 'c5e7': 15, 'a5b7': 16, 'g4g2': 17, 'e8c8': 18, 'c1f1': 19, 'a4a0': 20, 'g1i1': 21, 'd7d6': 22, 'h8d8': 23, 'a9a6': 24, 'a0a5': 25, 'h4h3': 26, 'i7i3': 27, 'a8a4': 28, 'e7e8': 29, 'g4c4': 30, 'c7c8': 31, 'a9a2': 32, 'f7h8': 33, 'g9h9': 34, 'i0c0': 35, 'd0b0': 36, 'c8c7': 37, 'e1a1': 38, 'i5i8': 39, 'd2f2': 40, 'b4b2': 41, 'a5e5': 42, 'c3c9': 43, 'e1d2': 44, 'g1b1': 45, 'g3g5': 46, 'i0g1': 47, 'e6d8': 48, 'd4g4': 49, 'f5e3': 50, 'i4b4': 51, 'g1g9': 52, 'c9a7': 53, 'f4i4': 54, 'i4g5': 55, 'f5f1': 56, 'e3c3': 57, 'i0i9': 58, 'c0d0': 59, 'e4b4': 60, 'e3i3': 61, 'f2f8': 62, 'f7d6': 63, 'h4h0': 64, 'g0g8': 65, 'h7g9': 66, 'e5d3': 67, 'c2d0': 68, 'b7f7': 69, 'e4e0': 70, 'h8i6': 71, 'g9g1': 72, 'f5b5': 73, 'g6g5': 74, 'h8h3': 75, 'b9d9': 76, 'b1a3': 77, 'g8b8': 78, 'c5i5': 79, 'e3e7': 80, 'c9i9': 81, 'a7b7': 82, 'a7c9': 83, 'f6f9': 84, 'h3i3': 85, 'i8g7': 86, 'a9h9': 87, 'a4a2': 88, 'h3h7': 89, 'a5b3': 90, 'h4i2': 91, 'b4h4': 92, 'i4i5': 93, 'f0g2': 94, 'e8c9': 95, 'b0b7': 96, 'c1c0': 97, 'h9h0': 98, 'a7i7': 99, 'i9i0': 100, 'b6e6': 101, 'a6a2': 102, 'h9d9': 103, 'f3d4': 104, 'd0c2': 105, 'e5f7': 106, 'c3b1': 107, 'c3d1': 108, 'f9h9': 109, 'b8b4': 110, 'f5e5': 111, 'd4b5': 112, 'e3e5': 113, 'b6d5': 114, 'f5g3': 115, 'h6e6': 116, 'e1c2': 117, 'g4f4': 118, 'f1f6': 119, 'g7g1': 120, 'h3h8': 121, 'a3f3': 122, 'd7c9': 123, 'a5a8': 124, 'c4c6': 125, 'i5i0': 126, 'd7f7': 127, 'e8i8': 128, 'f4f2': 129, 'd1h1': 130, 'i6b6': 131, 'f6f7': 132, 'i7i0': 133, 'i3c3': 134, 'c5h5': 135, 'c9c6': 136, 'b6c6': 137, 'b4b1': 138, 'e6e8': 139, 'd1c1': 140, 'e4d4': 141, 'b7d7': 142, 'd1i1': 143, 'f7e5': 144, 'c2a2': 145, 'e8g8': 146, 'c2e2': 147, 'h4f5': 148, 'f9e7': 149, 'i0i1': 150, 'e1e7': 151, 'g2g5': 152, 'd7d2': 153, 'h8h5': 154, 'f1g3': 155, 'e5e0': 156, 'a2c1': 157, 'e6e7': 158, 'i5b5': 159, 'h2h7': 160, 'b9b6': 161, 'a0d0': 162, 'h0h2': 163, 'a3b3': 164, 'b2d3': 165, 'b1b8': 166, 'g9a9': 167, 'f9b9': 168, 'b9a9': 169, 'a2e2': 170, 'd0d9': 171, 'e2e7': 172, 'c0c9': 173, 'd7h7': 174, 'a8a0': 175, 'f1a1': 176, 'c9c4': 177, 'i9a9': 178, 'h1i1': 179, 'h7c7': 180, 'b5b9': 181, 'b8b7': 182, 'g2d2': 183, 'e4f6': 184, 'c1b3': 185, 'i5i9': 186, 'a6a3': 187, 'e9e2': 188, 'h7f8': 189, 'b8b2': 190, 'b0c2': 191, 'd9e9': 192, 'h6h0': 193, 'c1a1': 194, 'e9e7': 195, 'g1i0': 196, 'e8d8': 197, 'i6c6': 198, 'e1e8': 199, 'g0a0': 200, 'd2d0': 201, 'a2c2': 202, 'c5c4': 203, 'b5d4': 204, 'g8g1': 205, 'i9f9': 206, 'b8a8': 207, 'e0e3': 208, 'a4a3': 209, 'd2e4': 210, 'h7e7': 211, 'i7e7': 212, 'd6c8': 213, 'h7i9': 214, 'a8g8': 215, 'a1a8': 216, 'e9g9': 217, 'b3b5': 218, 'g5g3': 219, 'f9e9': 220, 'c6c3': 221, 'd5d0': 222, 'c0a2': 223, 'c3c4': 224, 'g2h0': 225, 'e2a2': 226, 'a2a1': 227, 'a5a6': 228, 'g7g3': 229, 'i3h1': 230, 'e2e3': 231, 'h8g6': 232, 'f1h1': 233, 'd2b2': 234, 'c6c4': 235, 'i5g5': 236, 'i5i1': 237, 'a0e0': 238, 'i9i4': 239, 'a3b1': 240, 'h5g7': 241, 'h7h3': 242, 'e1f0': 243, 'g5h7': 244, 'a5a2': 245, 'd9d8': 246, 'i8i7': 247, 'c7c5': 248, 'h9f8': 249, 'g0d0': 250, 'f6d6': 251, 'f6d7': 252, 'd2e1': 253, 'd1g1': 254, 'b3f3': 255, 'c3h3': 256, 'd1f1': 257, 'b6b7': 258, 'f6e4': 259, 'f4d3': 260, 'f3f6': 261, 'e8c7': 262, 'b1a1': 263, 'h8h2': 264, 'e1f1': 265, 'i0i7': 266, 'd4f4': 267, 'g8e8': 268, 'a7a1': 269, 'c9b9': 270, 'd6b5': 271, 'b5c7': 272, 'h1h3': 273, 'd9d1': 274, 'h2e2': 275, 'f6f1': 276, 'd3d2': 277, 'h6f6': 278, 'g1g7': 279, 'i6i2': 280, 'c6c1': 281, 'd8b9': 282, 'i7i2': 283, 'h8h0': 284, 'a9e9': 285, 'i1i7': 286, 'a6b4': 287, 'd0e0': 288, 'i1h3': 289, 'c0c5': 290, 'a3i3': 291, 'h4g2': 292, 'g3e4': 293, 'f8b8': 294, 'a1b3': 295, 'd7e5': 296, 'e4e6': 297, 'e0d2': 298, 'i9b9': 299, 'e9e5': 300, 'e3d3': 301, 'b7b4': 302, 'b2b7': 303, 'a2g2': 304, 'b9b7': 305, 'e9i9': 306, 'd3e3': 307, 'g2h2': 308, 'e8e2': 309, 'h5h7': 310, 'g0g3': 311, 'f3i3': 312, 'c8d6': 313, 'h8b8': 314, 'g1g3': 315, 'e1i1': 316, 'b7g7': 317, 'i0i4': 318, 'c0g0': 319, 'f2f5': 320, 'f0a0': 321, 'h2a2': 322, 'b5d6': 323, 'c4c1': 324, 'h9h4': 325, 'd9c9': 326, 'h1h6': 327, 'f2f1': 328, 'f0i0': 329, 'b3b2': 330, 'b2b8': 331, 'd0a0': 332, 'b3b0': 333, 'd2e0': 334, 'g0g2': 335, 'e5e6': 336, 'h2i2': 337, 'd2d9': 338, 'a5a4': 339, 'c5a7': 340, 'b1d0': 341, 'c6c7': 342, 'd3d6': 343, 'f6i6': 344, 'g6g7': 345, 'i2i0': 346, 'h1h4': 347, 'a7f7': 348, 'f7f0': 349, 'b5a5': 350, 'e9a9': 351, 'e5f3': 352, 'g7g0': 353, 'b3c1': 354, 'f1i1': 355, 'd8d5': 356, 'e5e9': 357, 'h5g5': 358, 'b6a8': 359, 'f8i8': 360, 'g9f7': 361, 'b0b3': 362, 'g7g5': 363, 'd1d4': 364, 'a1e1': 365, 'a3a0': 366, 'i2g3': 367, 'c8e9': 368, 'g1c1': 369, 'b1b0': 370, 'h8i8': 371, 'f0f1': 372, 'a9i9': 373, 'c1d3': 374, 'b4i4': 375, 'i2h4': 376, 'g8d8': 377, 'e6g7': 378, 'g5e6': 379, 'c5e6': 380, 'h8g8': 381, 'a6h6': 382, 'e8e9': 383, 'd4h4': 384, 'e4a4': 385, 'e8d7': 386, 'd8d9': 387, 'd4c6': 388, 'i4g4': 389, 'h4g6': 390, 'd4d3': 391, 'i6i1': 392, 'f3g3': 393, 'd1f0': 394, 'i1f1': 395, 'c2c1': 396, 'a0a3': 397, 'h4a4': 398, 'h4e4': 399, 'c2e3': 400, 'd2f3': 401, 'a6b8': 402, 'e5e2': 403, 'f1c1': 404, 'g1d1': 405, 'd9d2': 406, 'i4c4': 407, 'h4h9': 408, 'd7c7': 409, 'e2e0': 410, 'c6i6': 411, 'c2b4': 412, 'h4d4': 413, 'i3e3': 414, 'i8i0': 415, 'b2b9': 416, 'c8b8': 417, 'b7b3': 418, 'f6h5': 419, 'i3g3': 420, 'c9g9': 421, 'e0e2': 422, 'a8a1': 423, 'c8a9': 424, 'f5f7': 425, 'g9g4': 426, 'c4d4': 427, 'f2f0': 428, 'h6h5': 429, 'i9h7': 430, 'c2a1': 431, 'f6c6': 432, 'i1a1': 433, 'h6i6': 434, 'i1i9': 435, 'g5g8': 436, 'e7e6': 437, 'f3f0': 438, 'i6d6': 439, 'e2c3': 440, 'b4b8': 441, 'a5g5': 442, 'e9e4': 443, 'f5f6': 444, 'a6a5': 445, 'b7c7': 446, 'g3g6': 447, 'b2g2': 448, 'c1h1': 449, 'c8b6': 450, 'e2g2': 451, 'c6e6': 452, 'c0d2': 453, 'c7c2': 454, 'a5a3': 455, 'h7f7': 456, 'a6e6': 457, 'h8h7': 458, 'i3i0': 459, 'g5g1': 460, 'i6i5': 461, 'a8a6': 462, 'g5i4': 463, 'g3f3': 464, 'f6f8': 465, 'a3d3': 466, 'e2f0': 467, 'd3b2': 468, 'd3a3': 469, 'e3h3': 470, 'g9g5': 471, 'b8b0': 472, 'd4c2': 473, 'b5f5': 474, 'h2h6': 475, 'c0c3': 476, 'd1d7': 477, 'd6g6': 478, 'i1g1': 479, 'f2d1': 480, 'f5f9': 481, 'c0e0': 482, 'b4c2': 483, 'a4a8': 484, 'a1a2': 485, 'd9b9': 486, 'b8d7': 487, 'b4b0': 488, 'h7h5': 489, 'f8h8': 490, 'h1h5': 491, 'h8f9': 492, 'b7a7': 493, 'a6a0': 494, 'd6b6': 495, 'b9b4': 496, 'b2c0': 497, 'a1d1': 498, 'b5a3': 499, 'f3a3': 500, 'd0f0': 501, 'd9i9': 502, 'e8f8': 503, 'c1e2': 504, 'e4c4': 505, 'f0f3': 506, 'b3c3': 507, 'i4i8': 508, 'h7h2': 509, 'c3c7': 510, 'i2i4': 511, 'd7b7': 512, 'f8f2': 513, 'i8h8': 514, 'i1i5': 515, 'a1a3': 516, 'd1b0': 517, 'f8f7': 518, 'f1e3': 519, 'g4h4': 520, 'f7b7': 521, 'e8e3': 522, 'a7b5': 523, 'd8d1': 524, 'i4i0': 525, 'e6f6': 526, 'h7h1': 527, 'i1b1': 528, 'f9f3': 529, 'b5b8': 530, 'g7g8': 531, 'f2f6': 532, 'd2a2': 533, 'a7a8': 534, 'a0i0': 535, 'c9c2': 536, 'g9f9': 537, 'i7i9': 538, 'c3a4': 539, 'g8i7': 540, 'f5c5': 541, 'g0e0': 542, 'e5c4': 543, 'g9i9': 544, 'h2c2': 545, 'h8h4': 546, 'i9i3': 547, 'c4c5': 548, 'i7i4': 549, 'h4f4': 550, 'g5g2': 551, 'h5h1': 552, 'c3g3': 553, 'd7d9': 554, 'g0f0': 555, 'i3h3': 556, 'd0d5': 557, 'b8d9': 558, 'b0d1': 559, 'g6d6': 560, 'f7e9': 561, 'g4e4': 562, 'f3d3': 563, 'a5a1': 564, 'h9h3': 565, 'f3f7': 566, 'd7f8': 567, 'c2c3': 568, 'b7i7': 569, 'a9b7': 570, 'c3c1': 571, 'b8h8': 572, 'f4g4': 573, 'f3f2': 574, 'h4f3': 575, 'b1b9': 576, 'h0g2': 577, 'd3i3': 578, 'b7d8': 579, 'a3g3': 580, 'e1d0': 581, 'g0i1': 582, 'i8i9': 583, 'h3c3': 584, 'i7h7': 585, 'd5c7': 586, 'g8h8': 587, 'd8f7': 588, 'e1f3': 589, 'd6d4': 590, 'f4g2': 591, 'i1h1': 592, 'b2b3': 593, 'g9c9': 594, 'a5d5': 595, 'i0g0': 596, 'e4c5': 597, 'g5g9': 598, 'f1f3': 599, 'd7f6': 600, 'i8c8': 601, 'g1g2': 602, 'a0f0': 603, 'e0g0': 604, 'a4c4': 605, 'b7b8': 606, 'g4g8': 607, 'd7e7': 608, 'e3g3': 609, 'i5g6': 610, 'c4c3': 611, 'i2f2': 612, 'h0h9': 613, 'd5c5': 614, 'a8a9': 615, 'f3d2': 616, 'f9g7': 617, 'e5g4': 618, 'h3h4': 619, 'f2b2': 620, 'a2b0': 621, 'f7g5': 622, 'a1f1': 623, 'd6d9': 624, 'a3e3': 625, 'c5c1': 626, 'e0g1': 627, 'd1d0': 628, 'a4g4': 629, 'i5i4': 630, 'g6g0': 631, 'g0g4': 632, 'c2c0': 633, 'h2h1': 634, 'g8g2': 635, 'g4g9': 636, 'c7c0': 637, 'f6f5': 638, 'g2g8': 639, 'c7b7': 640, 'b9b5': 641, 'g1f1': 642, 'f3b3': 643, 'a9a5': 644, 'd4c4': 645, 'a7d7': 646, 'i6h4': 647, 'i3d3': 648, 'i4i7': 649, 'a2c0': 650, 'a4b4': 651, 'c0c4': 652, 'g6f8': 653, 'a4a7': 654, 'c0i0': 655, 'i4i6': 656, 'd6d3': 657, 'g6h4': 658, 'e3g4': 659, 'c6d8': 660, 'i1g0': 661, 'i6i9': 662, 'c5b5': 663, 'f6f2': 664, 'd3d1': 665, 'e7e3': 666, 'g0g6': 667, 'c2g2': 668, 'f8f9': 669, 'f2h3': 670, 'i6h6': 671, 'e8f9': 672, 'c2a3': 673, 'f2h1': 674, 'b0e0': 675, 'g3c3': 676, 'i3i5': 677, 'f4f8': 678, 'e3f1': 679, 'b6d7': 680, 'b8c8': 681, 'i4g3': 682, 'g5f5': 683, 'c8h8': 684, 'g7f9': 685, 'i2h2': 686, 'd6h6': 687, 'h4b4': 688, 'd1d9': 689, 'c2d2': 690, 'a2b4': 691, 'd8h8': 692, 'a0a8': 693, 'i7g5': 694, 'e6i6': 695, 'c6b8': 696, 'i3b3': 697, 'e7e2': 698, 'b6c8': 699, 'g9i8': 700, 'b1i1': 701, 'd8d3': 702, 'g8g7': 703, 'd6f7': 704, 'd9e7': 705, 'b8g8': 706, 'f7a7': 707, 'c1c2': 708, 'g0i0': 709, 'f7i7': 710, 'd7e8': 711, 'd4d8': 712, 'c7h7': 713, 'c9a9': 714, 'g8h6': 715, 'b6a6': 716, 'e8e6': 717, 'e7e0': 718, 'c8f8': 719, 'd9a9': 720, 'h5h3': 721, 'b3d3': 722, 'e7c6': 723, 'c6c8': 724, 'e8b8': 725, 'd1d5': 726, 'g8g5': 727, 'f7g9': 728, 'd3g3': 729, 'd5e7': 730, 'f9d9': 731, 'c7e8': 732, 'c0b0': 733, 'e4e3': 734, 'f7f8': 735, 'c6a7': 736, 'h3i1': 737, 'g1g6': 738, 'd2e2': 739, 'd4d0': 740, 'f5e7': 741, 'g7i7': 742, 'd7d1': 743, 'c1c7': 744, 'e9g8': 745, 'a5h5': 746, 'e5e4': 747, 'd2f1': 748, 'a5c4': 749, 'h2d2': 750, 'a7a6': 751, 'b9d8': 752, 'a9f9': 753, 'h2g0': 754, 'g4g3': 755, 'f5f0': 756, 'f8d7': 757, 'd3c1': 758, 'c7g7': 759, 'e4h4': 760, 'h0h6': 761, 'a6a4': 762, 'a6a1': 763, 'h0i0': 764, 'g2a2': 765, 'h5i7': 766, 'i8i1': 767, 'a4d4': 768, 'c6g6': 769, 'b0i0': 770, 'h5f4': 771, 'g2g0': 772, 'i7h9': 773, 'g8e9': 774, 'c2b0': 775, 'e2c1': 776, 'a7a2': 777, 'd5d7': 778, 'a4i4': 779, 'i6i8': 780, 'f6f0': 781, 'g6g2': 782, 'c2c5': 783, 'd6b7': 784, 'c2h2': 785, 'f6a6': 786, 'g4f6': 787, 'a3a7': 788, 'f2a2': 789, 'g3d3': 790, 'f0e1': 791, 'f7d8': 792, 'b2i2': 793, 'd3d5': 794, 'b2a2': 795, 'i9d9': 796, 'g2e1': 797, 'b9e9': 798, 'd3c5': 799, 'g7i6': 800, 'i8h6': 801, 'f3f1': 802, 'e7d9': 803, 'a4b2': 804, 'g8e7': 805, 'g6c6': 806, 'f9g9': 807, 'g1e2': 808, 'a6c5': 809, 'g8g3': 810, 'h9g9': 811, 'c9e8': 812, 'a3a6': 813, 'f6g8': 814, 'i4h2': 815, 'c8e8': 816, 'f5d4': 817, 'b0a0': 818, 'f4c4': 819, 'c5a6': 820, 'c8c3': 821, 'b4b6': 822, 'g0g1': 823, 'h8f7': 824, 'b1b5': 825, 'g9g0': 826, 'a2i2': 827, 'i7a7': 828, 'd1e1': 829, 'i3g2': 830, 'e2f2': 831, 'a2c3': 832, 'e1c1': 833, 'c5c6': 834, 'i4d4': 835, 'a7c6': 836, 'e7e5': 837, 'i2i5': 838, 'd9d7': 839, 'g1e1': 840, 'c4c9': 841, 'h8h9': 842, 'h1h2': 843, 'a6i6': 844, 'g1g0': 845, 'a9a0': 846, 'd4d9': 847, 'a5c5': 848, 'd5d4': 849, 'h5h8': 850, 'i2g1': 851, 'c8e7': 852, 'i0i3': 853, 'd1d6': 854, 'd9d6': 855, 'd2h2': 856, 'b3b1': 857, 'b3b9': 858, 'h4h2': 859, 'e0e6': 860, 'h0d0': 861, 'd7b6': 862, 'g6g3': 863, 'b5c3': 864, 'b0b8': 865, 'h1h8': 866, 'e9c8': 867, 'g4g6': 868, 'b0b2': 869, 'c4d2': 870, 'c9h9': 871, 'g7g9': 872, 'd6d8': 873, 'e8g9': 874, 'e0f2': 875, 'g5c5': 876, 'e7g6': 877, 'e3d1': 878, 'g9b9': 879, 'i9i6': 880, 'h2b2': 881, 'd1f2': 882, 'b3i3': 883, 'e7d5': 884, 'f2g0': 885, 'e4d6': 886, 'f4h4': 887, 'a7h7': 888, 'b4e4': 889, 'f1f7': 890, 'f8f0': 891, 'd5e5': 892, 'h5i3': 893, 'e7g8': 894, 'e7f5': 895, 'c1c5': 896, 'd7b8': 897, 'e9h9': 898, 'a7c5': 899, 'f5i5': 900, 'h1h7': 901, 'c3d3': 902, 'g6g4': 903, 'g6h6': 904, 'g3g7': 905, 'g8a8': 906, 'd6d0': 907, 'i1i6': 908, 'b5b4': 909, 'b7b5': 910, 'b0d0': 911, 'e2c0': 912, 'h9b9': 913, 'g5i6': 914, 'c3b5': 915, 'd1d8': 916, 'f4f1': 917, 'g7e7': 918, 'f4e2': 919, 'e2g0': 920, 'd6d1': 921, 'a8i8': 922, 'g3g2': 923, 'd3e5': 924, 'd0g0': 925, 'e8e5': 926, 'h1i3': 927, 'b6c4': 928, 'g6e6': 929, 'g2g4': 930, 'g5h5': 931, 'f5h4': 932, 'i3g4': 933, 'g4g5': 934, 'd5d1': 935, 'i9c9': 936, 'b2b0': 937, 'e7b7': 938, 'd3f3': 939, 'f4b4': 940, 'd5f5': 941, 'g5h3': 942, 'h7h9': 943, 'a0b0': 944, 'f0c0': 945, 'd8c8': 946, 'a5c6': 947, 'a0a2': 948, 'g1f3': 949, 'b3b7': 950, 'h0g0': 951, 'e9e8': 952, 'e5i5': 953, 'b6g6': 954, 'g5i7': 955, 'd1d2': 956, 'e7c5': 957, 'b8d8': 958, 'h9h1': 959, 'f1d0': 960, 'a2a8': 961, 'b3a5': 962, 'b1f1': 963, 'h5d5': 964, 'a7g7': 965, 'd2b3': 966, 'a1c0': 967, 'd9g9': 968, 'f2g2': 969, 'h6b6': 970, 'g4d4': 971, 'g3g1': 972, 'h7a7': 973, 'a0a7': 974, 'c0e2': 975, 'c7c1': 976, 'g2i3': 977, 'h4h8': 978, 'b4b9': 979, 'f0f5': 980, 'a6g6': 981, 'e7c9': 982, 'e3c4': 983, 'g2f2': 984, 'f3c3': 985, 'h6h2': 986, 'h5e5': 987, 'c4e2': 988, 'd3f4': 989, 'd4d1': 990, 'g3b3': 991, 'b0b1': 992, 'a0b2': 993, 'e6e2': 994, 'c8c4': 995, 'd2b1': 996, 'h0h8': 997, 'c1d1': 998, 'g7f7': 999, 'g3f5': 1000, 'i6g7': 1001, 'e6h6': 1002, 'i9i5': 1003, 'g2e2': 1004, 'i3i6': 1005, 'a8c8': 1006, 'b0g0': 1007, 'c4c7': 1008, 'd8f9': 1009, 'g4h2': 1010, 'g1i2': 1011, 'a4c3': 1012, 'd4b4': 1013, 'h6h8': 1014, 'g0h0': 1015, 'b9c9': 1016, 'f8g8': 1017, 'd0d7': 1018, 'h0a0': 1019, 'a1c1': 1020, 'a6f6': 1021, 'h3h9': 1022, 'g9i7': 1023, 'c1c8': 1024, 'b0b9': 1025, 'e6a6': 1026, 'c6d6': 1027, 'i5i2': 1028, 'a8a3': 1029, 'c0h0': 1030, 'g0h2': 1031, 'h8h1': 1032, 'e2h2': 1033, 'a3a4': 1034, 'c5c7': 1035, 'i5i7': 1036, 'c1b1': 1037, 'b0b5': 1038, 'g5d5': 1039, 'g3i4': 1040, 'b7h7': 1041, 'e2g1': 1042, 'e4f2': 1043, 'f3h2': 1044, 'e5d5': 1045, 'c6c2': 1046, 'e6g5': 1047, 'e6c7': 1048, 'c6a5': 1049, 'g2c2': 1050, 'e3f5': 1051, 'b4a2': 1052, 'a7a0': 1053, 'e3g2': 1054, 'h9h2': 1055, 'i2a2': 1056, 'i8f8': 1057, 'b2b6': 1058, 'i1i3': 1059, 'f0h0': 1060, 'f4d5': 1061, 'd2d1': 1062, 'h1f1': 1063, 'b7e7': 1064, 'g4e2': 1065, 'b2b4': 1066, 'h6c6': 1067, 'h5b5': 1068, 'f8a8': 1069, 'e1e3': 1070, 'g3g0': 1071, 'g4i4': 1072, 'e3f3': 1073, 'b6b2': 1074, 'b1h1': 1075, 'i7f7': 1076, 'h3a3': 1077, 'f2e1': 1078, 'f4f3': 1079, 'd8b7': 1080, 'd6c6': 1081, 'e0f0': 1082, 'f7c7': 1083, 'a9a3': 1084, 'f6g6': 1085, 'e5e3': 1086, 'f1g1': 1087, 'a3a1': 1088, 'i9e9': 1089, 'd3d0': 1090, 'b1d1': 1091, 'b0b6': 1092, 'd2g2': 1093, 'g5g7': 1094, 'g7g4': 1095, 'g9d9': 1096, 'i5h3': 1097, 'b3c5': 1098, 'i1c1': 1099, 'd7d8': 1100, 'b8e8': 1101, 'c7c3': 1102, 'e4g5': 1103, 'h1g3': 1104, 'd3d7': 1105, 'a6b6': 1106, 'c2f2': 1107, 'a9d9': 1108, 'd7a7': 1109, 'd1c3': 1110, 'g6e7': 1111, 'i3i9': 1112, 'f2h2': 1113, 'f1f0': 1114, 'h7h0': 1115, 'c2b2': 1116, 'h9h7': 1117, 'd5d2': 1118, 'd5f4': 1119, 'h7h8': 1120, 'f9f0': 1121, 'd5b6': 1122, 'f3f5': 1123, 'g6i5': 1124, 'd2c2': 1125, 'f9f2': 1126, 'g4h6': 1127, 'b5h5': 1128, 'h9f9': 1129, 'd4e2': 1130, 'g4g1': 1131, 'f1h0': 1132, 'i5i3': 1133, 'd8d2': 1134, 'c8a7': 1135, 'f8c8': 1136, 'c9c8': 1137, 'g9g7': 1138, 'c7c9': 1139, 'e9f9': 1140, 'e6b6': 1141, 'f7h6': 1142, 'f5h6': 1143, 'd8d7': 1144, 'd6c4': 1145, 'i5a5': 1146, 'f8f4': 1147, 'a6d6': 1148, 'e7d7': 1149, 'a4h4': 1150, 'e6e5': 1151, 'h3h1': 1152, 'a3h3': 1153, 'g4g0': 1154, 'g3g4': 1155, 'e5g5': 1156, 'h3b3': 1157, 'h7i5': 1158, 'i6g6': 1159, 'h5h6': 1160, 'd8d6': 1161, 'd5g5': 1162, 'f3e3': 1163, 'e7h7': 1164, 'e1c0': 1165, 'b0f0': 1166, 'h2h3': 1167, 'i8i5': 1168, 'g1g5': 1169, 'c3f3': 1170, 'e6d4': 1171, 'g2h4': 1172, 'f1e1': 1173, 'i2c2': 1174, 'b4b3': 1175, 'h6g4': 1176, 'i2i9': 1177, 'i8g9': 1178, 'h1f0': 1179, 'd3e1': 1180, 'i2h0': 1181, 'h5c5': 1182, 'b6b9': 1183, 'c9c3': 1184, 'e8d6': 1185, 'f7h7': 1186, 'b7c9': 1187, 'g3i2': 1188, 'a2b2': 1189, 'c5a4': 1190, 'g1e0': 1191, 'e9e3': 1192, 'i5h5': 1193, 'i8b8': 1194, 'c4d6': 1195, 'b4a6': 1196, 'c8i8': 1197, 'i0d0': 1198, 'e9e6': 1199, 'g7i8': 1200, 'a1g1': 1201, 'h9h8': 1202, 'd3f2': 1203, 'd3b3': 1204, 'h5g3': 1205, 'i7i5': 1206, 'b2c2': 1207, 'd1e3': 1208, 'd5c3': 1209, 'd0i0': 1210, 'f0e2': 1211, 'g9g6': 1212, 'e2d0': 1213, 'e2d2': 1214, 'h9g7': 1215, 'f1f8': 1216, 'c0c7': 1217, 'g5e5': 1218, 'h1a1': 1219, 'g8g4': 1220, 'h7i7': 1221, 'c8c9': 1222, 'e0i0': 1223, 'e9d7': 1224, 'f0g0': 1225, 'f2f4': 1226, 'g3g9': 1227, 'i2g2': 1228, 'e1e6': 1229, 'a2a6': 1230, 'h2i4': 1231, 'f4f7': 1232, 'h5i5': 1233, 'e3d5': 1234, 'd7d0': 1235, 'i8i2': 1236, 'h6h3': 1237, 'e0e9': 1238, 'i6i7': 1239, 'f6f3': 1240, 'c3e3': 1241, 'e5c6': 1242, 'f2c2': 1243, 'a2a5': 1244, 'e3c2': 1245, 'i8i4': 1246, 'e3e9': 1247, 'g5i5': 1248, 'h3f2': 1249, 'g4i3': 1250, 'b4a4': 1251, 'a9a4': 1252, 'd2d3': 1253, 'e7e9': 1254, 'h0f0': 1255, 'c7d7': 1256, 'a5b5': 1257, 'e7e4': 1258, 'e8g7': 1259, 'g3g8': 1260, 'i3h5': 1261, 'f8f5': 1262, 'd6e8': 1263, 'h0h4': 1264, 'c3a2': 1265, 'g8g0': 1266, 'i9i7': 1267, 'h6d6': 1268, 'a7a5': 1269, 'i6i4': 1270, 'b3a1': 1271, 'g2b2': 1272, 'b5d5': 1273, 'h7b7': 1274, 'h2f1': 1275, 'c5f5': 1276, 'f2f7': 1277, 'g7a7': 1278, 'h7g5': 1279, 'd4a4': 1280, 'c4b4': 1281, 'd8g8': 1282, 'd4e6': 1283, 'h7g7': 1284, 'a9b9': 1285, 'b3b6': 1286, 'h0c0': 1287, 'c1c6': 1288, 'd4i4': 1289, 'h6f7': 1290, 'e5d7': 1291, 'c6e5': 1292, 'd2c0': 1293, 'c1e0': 1294, 'c0a0': 1295, 'd2c4': 1296, 'c3a3': 1297, 'h3h6': 1298, 'b8a6': 1299, 'd5b4': 1300, 'g5g4': 1301, 'c6h6': 1302, 'h0i2': 1303, 'f4f9': 1304, 'c5c3': 1305, 'h6h7': 1306, 'b2h2': 1307, 'b5b2': 1308, 'a0a6': 1309, 'g3f1': 1310, 'c5b7': 1311, 'c1a2': 1312, 'i5i6': 1313, 'd7c5': 1314, 'h6a6': 1315, 'c2c8': 1316, 'g2f4': 1317, 'h0e0': 1318, 'h5f6': 1319, 'c7c4': 1320, 'c0f0': 1321, 'b1c1': 1322, 'i1i8': 1323, 'c4e4': 1324, 'b7b9': 1325, 'd8d0': 1326, 'h1c1': 1327, 'f6f4': 1328, 'f4d4': 1329, 'g2g9': 1330, 'b2e2': 1331, 'e8e0': 1332, 'c5d7': 1333, 'i8i6': 1334, 'a8b6': 1335, 'g8c8': 1336, 'i5g4': 1337, 'i0i2': 1338, 'i5h7': 1339, 'i1i2': 1340, 'd0e1': 1341, 'b9c7': 1342, 'a8d8': 1343, 'i9i8': 1344, 'i2g4': 1345, 'h3f4': 1346, 'a9a8': 1347, 'g0g9': 1348, 'f4f6': 1349, 'd5d8': 1350, 'b6d6': 1351, 'f8h9': 1352, 'd0h0': 1353, 'b6a4': 1354, 'b5b7': 1355, 'f6h7': 1356, 'b4c6': 1357, 'i3i7': 1358, 'g7e6': 1359, 'h9a9': 1360, 'e3e8': 1361, 'e9d9': 1362, 'h6h4': 1363, 'b0a2': 1364, 'e7f7': 1365, 'g7e8': 1366, 'b6b0': 1367, 'c6c5': 1368, 'f8f6': 1369, 'b2d1': 1370, 'f8f1': 1371, 'd5d3': 1372, 'c3c2': 1373, 'e1e2': 1374, 'h5h2': 1375, 'a1a4': 1376, 'h3e3': 1377, 'g4i5': 1378, 'a6a9': 1379, 'c7a7': 1380, 'c9c1': 1381, 'g6f4': 1382, 'g6h8': 1383, 'a0a1': 1384, 'h8c8': 1385, 'd7d4': 1386, 'g6e5': 1387, 'd5e3': 1388, 'a0g0': 1389, 'i8g8': 1390, 'i1d1': 1391, 'h7h6': 1392, 'e3e6': 1393, 'g7c7': 1394, 'f9d8': 1395, 'f3h4': 1396, 'a5a7': 1397, 'c4a2': 1398, 'g3e2': 1399, 'c3i3': 1400, 'e2f4': 1401, 'e0d0': 1402, 'f1h2': 1403, 'f8e8': 1404, 'c6b6': 1405, 'b3b8': 1406, 'd6d7': 1407, 'h2g4': 1408, 'c9b7': 1409, 'd4d5': 1410, 'h3d3': 1411, 'i3i4': 1412, 'i2e2': 1413, 'f0f6': 1414, 'e2c2': 1415, 'c4c0': 1416, 'b4f4': 1417, 'h4h1': 1418, 'd4f5': 1419, 'g5g0': 1420, 'i7i1': 1421, 'f2i2': 1422, 'f9f6': 1423, 'c0b2': 1424, 'c4f4': 1425, 'g5f3': 1426, 'h5h4': 1427, 'i4i1': 1428, 'd9d5': 1429, 'a4c5': 1430, 'c0c6': 1431, 'h8f8': 1432, 'e1g2': 1433, 'd9e8': 1434, 'e0b0': 1435, 'c4g4': 1436, 'e6g6': 1437, 'd6d2': 1438, 'e5g6': 1439, 'f3e1': 1440, 'f4f5': 1441, 'f5f3': 1442, 'd9f8': 1443, 'f9a9': 1444, 'b1b4': 1445, 'e3e0': 1446, 'g6i6': 1447, 'f8d8': 1448, 'a8a7': 1449, 'f4f0': 1450, 'i6a6': 1451, 'e4c3': 1452, 'c4a5': 1453, 'c4b2': 1454, 'c5d3': 1455, 'g2g1': 1456, 'a2c4': 1457, 'e8f7': 1458, 'c9c0': 1459, 'f3g1': 1460, 'e9f7': 1461, 'b9b0': 1462, 'g7h7': 1463, 'c8g8': 1464, 'a8f8': 1465, 'e6e3': 1466, 'g0e1': 1467, 'f9c9': 1468, 'e0e7': 1469, 'd2i2': 1470, 'e3e2': 1471, 'e4e8': 1472, 'e2g3': 1473, 'h9i9': 1474, 'd8i8': 1475, 'e8h8': 1476, 'i7g6': 1477, 'd4b3': 1478, 'g8g6': 1479, 'b8b9': 1480, 'e8d9': 1481, 'f7g7': 1482, 'f7e8': 1483, 'h5h0': 1484, 'e9e0': 1485, 'e3a3': 1486, 'b2a4': 1487, 'f9f4': 1488, 'g7g2': 1489, 'c1i1': 1490, 'c5c2': 1491, 'd5d6': 1492, 'a4a5': 1493, 'i4i9': 1494, 'a4e4': 1495, 'f0f8': 1496, 'f1d2': 1497, 'b8b5': 1498, 'h8a8': 1499, 'c2c7': 1500, 'i5d5': 1501, 'c7i7': 1502, 'i8d8': 1503, 'f7d7': 1504, 'h7d7': 1505, 'f2f9': 1506, 'e0a0': 1507, 'g5g6': 1508, 'h4g4': 1509, 'a9g9': 1510, 'c6c0': 1511, 'h1f2': 1512, 'a9a1': 1513, 'd5a5': 1514, 'b8c6': 1515, 'g1g8': 1516, 'd1b1': 1517, 'd1b2': 1518, 'd4d7': 1519, 'h4c4': 1520, 'h4h5': 1521, 'h3f3': 1522, 'd6f6': 1523, 'a7b9': 1524, 'b3d2': 1525, 'h6h9': 1526, 'f5g7': 1527, 'h6g8': 1528, 'f5h5': 1529, 'b7c5': 1530, 'i9i2': 1531, 'e0e8': 1532, 'a1i1': 1533, 'b7a5': 1534, 'd8e8': 1535, 'i3i8': 1536, 'i7g7': 1537, 'b9b8': 1538, 'c4a4': 1539, 'b3a3': 1540, 'e6d6': 1541, 'b8f8': 1542, 'd9f9': 1543, 'h6h1': 1544, 'c3e2': 1545, 'g6i7': 1546, 'e5a5': 1547, 'c5c0': 1548, 'a7c7': 1549, 'c3c5': 1550, 'c3b3': 1551, 'a9c9': 1552, 'e8f6': 1553, 'b8b3': 1554, 'f8d9': 1555, 'h3h0': 1556, 'e3b3': 1557, 'f3f4': 1558, 'e7g9': 1559, 'd2d4': 1560, 'e7c8': 1561, 'h4h7': 1562, 'a2a7': 1563, 'g3h5': 1564, 'i0e0': 1565, 'f3f8': 1566, 'c9e7': 1567, 'b6b1': 1568, 'g1g4': 1569, 'g8f8': 1570, 'd6e6': 1571, 'h1h0': 1572, 'c1e1': 1573, 'c7f7': 1574, 'g8i8': 1575, 'h9e9': 1576, 'd6i6': 1577, 'e1d1': 1578, 'c2d4': 1579, 'h1b1': 1580, 'c6d4': 1581, 'f5g5': 1582, 'b1d2': 1583, 'i6i0': 1584, 'f4g6': 1585, 'i7b7': 1586, 'f5f2': 1587, 'd8f8': 1588, 'd5b5': 1589, 'a8h8': 1590, 'f7f9': 1591, 'c6b4': 1592, 'g8g9': 1593, 'd7g7': 1594, 'a1b1': 1595, 'g7b7': 1596, 'f5f8': 1597, 'g8i9': 1598, 'b0b4': 1599, 'e2d4': 1600, 'g0i2': 1601, 'f9i9': 1602, 'f8g6': 1603, 'd3d8': 1604, 'e2c4': 1605, 'c1g1': 1606, 'e0c0': 1607, 'c5e5': 1608, 'b6b8': 1609, 'd8a8': 1610, 'c3e4': 1611, 'e4e9': 1612, 'c5c8': 1613, 'a9c8': 1614, 'a5a0': 1615, 'e6e9': 1616, 'e5h5': 1617, 'e4e1': 1618, 'd4d6': 1619, 'f2e4': 1620, 'c3c6': 1621, 'c2c4': 1622, 'i5c5': 1623, 'i3i2': 1624, 'd5f6': 1625, 'c7d5': 1626, 'b2f2': 1627, 'e6f8': 1628, 'h8e8': 1629, 'e6f4': 1630, 'i3i1': 1631, 'i6f6': 1632, 'g0g5': 1633, 'f5d5': 1634, 'b8i8': 1635, 'd9d3': 1636, 'c7e6': 1637, 'c2c6': 1638, 'e5e1': 1639, 'i6e6': 1640, 'a4f4': 1641, 'a5i5': 1642, 'd7i7': 1643, 'b4b7': 1644, 'g5a5': 1645, 'e1e4': 1646, 'g7f5': 1647, 'f4h3': 1648, 'g6a6': 1649, 'i5e5': 1650, 'e7a7': 1651, 'i4e4': 1652, 'g2i2': 1653, 'e2e1': 1654, 'a1a5': 1655, 'f0f7': 1656, 'b2b5': 1657, 'e8a8': 1658, 'b9b1': 1659, 'i2b2': 1660, 'e1h1': 1661, 'b3e3': 1662, 'f0h1': 1663, 'g2g7': 1664, 'e0e5': 1665, 'd2d6': 1666, 'i0h2': 1667, 'g4f2': 1668, 'b6f6': 1669, 'c6c9': 1670, 'i1e1': 1671, 'h2f3': 1672, 'f6h6': 1673, 'e1e0': 1674, 'c3c0': 1675, 'h3g5': 1676, 'i9g9': 1677, 'c5a5': 1678, 'b7b0': 1679, 'a8e8': 1680, 'h6g6': 1681, 'b6i6': 1682, 'h9i7': 1683, 'f6b6': 1684, 'f4e6': 1685, 'a2a9': 1686, 'i8a8': 1687, 'b2c4': 1688, 'c4i4': 1689, 'd3d9': 1690, 'f7f5': 1691, 'c0e1': 1692, 'd3h3': 1693, 'b1g1': 1694, 'a4a1': 1695, 'c2i2': 1696, 'c8c2': 1697, 'h7f6': 1698, 'f1b1': 1699, 'g3a3': 1700, 'i4h6': 1701, 'b1c3': 1702, 'e8e1': 1703, 'd7d3': 1704, 'c6f6': 1705, 'f3g5': 1706, 'i6h8': 1707, 'i1i4': 1708, 'a0a9': 1709, 'g5e4': 1710, 'h5h9': 1711, 'b5i5': 1712, 'a1a6': 1713, 'g0f2': 1714, 'e4d2': 1715, 'h6f5': 1716, 'a2h2': 1717, 'c9d9': 1718, 'c4b6': 1719, 'c8c6': 1720, 'e9b9': 1721, 'g6g9': 1722, 'f5a5': 1723, 'a7c8': 1724, 'g2i1': 1725, 'c0c1': 1726, 'f0b0': 1727, 'b4d3': 1728, 'c1c4': 1729, 'd9b8': 1730, 'f9h8': 1731, 'b8b1': 1732, 'h2i0': 1733, 'd8d4': 1734, 'c7c6': 1735, 'f1f9': 1736, 'b9i9': 1737, 'a8a2': 1738, 'b9b3': 1739, 'a6a7': 1740, 'g2e3': 1741, 'c6e7': 1742, 'h5f5': 1743, 'g4e5': 1744, 'c0c2': 1745, 'f6e6': 1746, 'h0f1': 1747, 'd3c3': 1748, 'e7e1': 1749, 'i0f0': 1750, 'd5i5': 1751, 'd0d4': 1752, 'a0h0': 1753, 'g6f6': 1754, 'd0d1': 1755, 'g4a4': 1756, 'i7g8': 1757, 'i0a0': 1758, 'a3c3': 1759, 'e1d3': 1760, 'a2a3': 1761, 'a5a9': 1762, 'f9f7': 1763, 'b9a7': 1764, 'f9f1': 1765, 'h1e1': 1766, 'e0e4': 1767, 'f1f5': 1768, 'e4e5': 1769, 'a3b5': 1770, 'g9g2': 1771, 'a9a7': 1772, 'i0i8': 1773, 'i3a3': 1774, 'e6e4': 1775, 'i7i8': 1776, 'f2d3': 1777, 'f1f2': 1778, 'g4e3': 1779, 'b6h6': 1780, 'i0b0': 1781, 'c1a0': 1782, 'c5e4': 1783, 'a6c6': 1784, 'e1g1': 1785, 'h7h4': 1786, 'a4a6': 1787, 'c1c3': 1788, 'e5b5': 1789, 'a3a9': 1790, 'g8f6': 1791, 'h8h6': 1792, 'd0f1': 1793, 'e5e7': 1794, 'f9f8': 1795, 'b6b5': 1796, 'f7f3': 1797, 'f8e6': 1798, 'a1h1': 1799, 'h1d1': 1800, 'g1a1': 1801, 'f4h5': 1802, 'i2g0': 1803, 'i7c7': 1804, 'e9c9': 1805, 'c8c1': 1806, 'h2h0': 1807, 'i6i3': 1808, 'c7a6': 1809, 'i4a4': 1810, 'i7d7': 1811, 'c3d5': 1812, 'e2b2': 1813, 'g9e8': 1814, 'b7b1': 1815, 'i7i6': 1816, 'e2e6': 1817, 'b9f9': 1818, 'a6c7': 1819, 'd5d9': 1820, 'g9e9': 1821, 'g6g1': 1822, 'h2h9': 1823, 'h2h4': 1824, 'i2i3': 1825, 'g4b4': 1826, 'b9h9': 1827, 'b1b3': 1828, 'b2b1': 1829, 'g9e7': 1830, 'g0e2': 1831, 'b5b0': 1832, 'g7h5': 1833, 'c9e9': 1834, 'f4e4': 1835, 'd2d5': 1836, 'e6e1': 1837, 'b5e5': 1838, 'c5b3': 1839, 'e4e2': 1840, 'h3i5': 1841, 'h2f2': 1842, 'd7e9': 1843, 'e4g4': 1844, 'f6g4': 1845, 'i5f5': 1846, 'e7c7': 1847, 'd0d6': 1848, 'a4a9': 1849, 'c7b9': 1850, 'h2g2': 1851, 'a4b6': 1852, 'f7f2': 1853, 'd8b8': 1854, 'e4i4': 1855, 'c9d7': 1856, 'f2e2': 1857, 'f2e0': 1858, 'e6c5': 1859, 'e0h0': 1860, 'i0i6': 1861, 'd0b1': 1862, 'a3a8': 1863, 'd0d3': 1864, 'h1h9': 1865, 'd6a6': 1866, 'g9g8': 1867, 'e2e8': 1868, 'c3c8': 1869, 'i0h0': 1870, 'f7f1': 1871, 'c9c7': 1872, 'g2f0': 1873, 'h2h8': 1874, 'h0h1': 1875, 'c4e3': 1876, 'a0c0': 1877, 'f1d1': 1878, 'g5b5': 1879, 'c4a3': 1880, 'g0g7': 1881, 'd3d4': 1882, 'h0h5': 1883, 'c8c0': 1884, 'c1c9': 1885, 'b9g9': 1886, 'b3g3': 1887, 'a2d2': 1888, 'e7g5': 1889, 'a1a0': 1890, 'g7d7': 1891, 'b4d5': 1892, 'g5e7': 1893, 'a7a9': 1894, 'c2e1': 1895, 'a8a5': 1896, 'c0c8': 1897, 'g2g6': 1898, 'f0f2': 1899, 'h0h3': 1900, 'a3c2': 1901, 'g7h9': 1902, 'a3a2': 1903, 'c0a1': 1904, 'g3h1': 1905, 'f3h3': 1906, 'f4a4': 1907, 'a2a4': 1908, 'f0d1': 1909, 'f0f9': 1910, 'e2e4': 1911, 'a7e7': 1912, 'e1e9': 1913, 'd9c7': 1914, 'e7i7': 1915, 'h2h5': 1916, 'i9g8': 1917, 'f5f4': 1918, 'a2a0': 1919, 'b2d2': 1920, 'b1b2': 1921, 'd0d2': 1922, 'f0e0': 1923, 'a2f2': 1924, 'f2f3': 1925, 'f0d0': 1926, 'd6e4': 1927, 'e5e8': 1928, 'b7b6': 1929, 'f8h7': 1930, 'e7f9': 1931, 'b1e1': 1932, 'c9a8': 1933, 'a8c7': 1934, 'd4f3': 1935, 'e1g0': 1936, 'c7b5': 1937, 'f3f9': 1938, 'f3e5': 1939, 'b2a0': 1940, 'i2i7': 1941, 'f5d6': 1942, 'b5b6': 1943, 'e2e5': 1944, 'c7d9': 1945, 'e0c1': 1946, 'e1e5': 1947, 'i2d2': 1948, 'c9c5': 1949, 'c4e5': 1950, 'f1f4': 1951, 'f6d5': 1952, 'd7d5': 1953, 'b7b2': 1954, 'e4e7': 1955, 'h9c9': 1956, 'i0i5': 1957, 'h4h6': 1958, 'c4c2': 1959, 'f0f4': 1960, 'd2d7': 1961, 'i4f4': 1962, 'b1b7': 1963, 'f2d2': 1964, 'i4i3': 1965, 'g1h1': 1966, 'd0c0': 1967, 'e7g7': 1968, 'c7e7': 1969, 'g0b0': 1970, 'h3g3': 1971, 'e6e0': 1972, 'e5f5': 1973, 'e8e7': 1974, 'b0h0': 1975, 'b3b4': 1976, 'b6b4': 1977, 'b8b6': 1978, 'c7a8': 1979, 'a7a4': 1980, 'f7f6': 1981, 'c8a8': 1982, 'i8i3': 1983, 'd6d5': 1984, 'e1b1': 1985, 'd6f5': 1986, 'e0e1': 1987, 'c5c9': 1988, 'c4h4': 1989, 'b5c5': 1990, 'f2g4': 1991, 'g5f7': 1992, 'g6g8': 1993, 'b5b1': 1994, 'f9e8': 1995, 'e3e4': 1996, 'g3h3': 1997, 'a3c4': 1998, 'h6i4': 1999, 'a8c9': 2000, 'a0c1': 2001, 'i8e8': 2002, 'd0d8': 2003, 'a7a3': 2004, 'd2d8': 2005, 'h6i8': 2006, 'd0e2': 2007, 'c6a6': 2008, 'd8c6': 2009, 'i1i0': 2010, 'b5b3': 2011, 'e1f2': 2012, 'g3i3': 2013, 'g4i2': 2014, 'd3b4': 2015, 'h5a5': 2016, 'f8f3': 2017, 'e6c6': 2018, 'b9b2': 2019, 'a6a8': 2020, 'a5f5': 2021, 'i2i6': 2022, 'b4b5': 2023, 'b5a7': 2024, 'g9g3': 2025, 'i4h4': 2026, 'e9e1': 2027, 'c8c5': 2028, 'd9d4': 2029, 'd9h9': 2030, 'h9h6': 2031, 'a0a4': 2032, 'g4g7': 2033, 'i7g9': 2034, 'a1c2': 2035, 'd4e4': 2036, 'b7d6': 2037, 'd5h5': 2038, 'f7e7': 2039, 'c4c8': 2040, 'h4i4': 2041, 'a3a5': 2042, 'd8e6': 2043, 'i9i1': 2044, 'b1b6': 2045, 'b4d4': 2046, 'g9h7': 2047, 'a1a7': 2048, 'a1a9': 2049, 'a8b8': 2050, 'h0h7': 2051, 'b4g4': 2052, 'c2c9': 2053, 'h0b0': 2054, 'b7a9': 2055, 'g6b6': 2056, 'd4d2': 2057, 'e8e4': 2058, 'f7f4': 2059, 'i6g5': 2060, 'h3g1': 2061, 'i1g2': 2062, 'f9f5': 2063, 'i2i1': 2064, 'i2i8': 2065, 'c5g5': 2066, 'g1h3': 2067, 'c8d8': 2068, 'h4i6': 2069, 'b4c4': 2070, 'i9h9': 2071, 'g7g6': 2072, 'c9f9': 2073, 'h3h2': 2074, 'b3d4': 2075, 'h1g1': 2076, 'b3h3': 2077, 'b6b3': 2078, 'f6e8': 2079, 'd9d0': 2080, 'b0c0': 2081, 'e4g3': 2082, 'h9h5': 2083, 'i4i2': 2084, 'e5c5': 2085})\n"
     ]
    }
   ],
   "source": [
    "columns = \"abcdefghi\"\n",
    "rows = range(0, 10)\n",
    "moves: set[str] = set()\n",
    "\n",
    "# unbounded moves\n",
    "for r in rows:\n",
    "    for c in range(len(columns)):\n",
    "        from_pos = f\"{columns[c]}{r}\"\n",
    "        # horizontal moves\n",
    "        for cc in range(len(columns)):\n",
    "            if cc != c:\n",
    "                to_pos = f\"{columns[cc]}{r}\"\n",
    "                moves.add(f\"{from_pos}{to_pos}\")\n",
    "        # vertical moves\n",
    "        for rr in rows:\n",
    "            if rr != r:\n",
    "                to_pos = f\"{columns[c]}{rr}\"\n",
    "                moves.add(f\"{from_pos}{to_pos}\")\n",
    "        # horse moves\n",
    "        horse_directions = [\n",
    "            (-2, -1),\n",
    "            (-1, -2),\n",
    "            (1, -2),\n",
    "            (2, -1),\n",
    "            (2, 1),\n",
    "            (1, 2),\n",
    "            (-1, 2),\n",
    "            (-2, 1),\n",
    "        ]\n",
    "        from_pos = f\"{columns[c]}{r}\"\n",
    "        for dc, dr in horse_directions:\n",
    "            nc, nr = c + dc, r + dr\n",
    "            if 0 <= nc < len(columns) and 0 <= nr < 10:\n",
    "                to_pos = f\"{columns[nc]}{nr}\"\n",
    "                moves.add(f\"{from_pos}{to_pos}\")\n",
    "\n",
    "# bounded moves\n",
    "# elephants\n",
    "r_elephant = [\n",
    "    [\"a2\", \"c0\"],\n",
    "    [\"a2\", \"c4\"],\n",
    "    [\"c0\", \"e2\"],\n",
    "    [\"c4\", \"e2\"],\n",
    "    [\"e2\", \"g0\"],\n",
    "    [\"e2\", \"g4\"],\n",
    "    [\"g0\", \"i2\"],\n",
    "    [\"g4\", \"i2\"],\n",
    "]\n",
    "b_elephant = [\n",
    "    [\"a7\", \"c5\"],\n",
    "    [\"a7\", \"c9\"],\n",
    "    [\"c5\", \"e7\"],\n",
    "    [\"c9\", \"e7\"],\n",
    "    [\"e7\", \"g5\"],\n",
    "    [\"e7\", \"g9\"],\n",
    "    [\"g5\", \"i7\"],\n",
    "    [\"g9\", \"i7\"],\n",
    "]\n",
    "# avisor\n",
    "r_advisor = [[\"e1\", \"d0\"], [\"e1\", \"d2\"], [\"e1\", \"f0\"], [\"e1\", \"f2\"]]\n",
    "b_advisor = [[\"e8\", \"d9\"], [\"e8\", \"d7\"], [\"e8\", \"f9\"], [\"e8\", \"f7\"]]\n",
    "# kings\n",
    "r_king = [[\"e1\", \"e0\"], [\"e1\", \"e2\"], [\"e1\", \"d1\"], [\"e1\", \"f1\"]]\n",
    "b_king = [[\"e8\", \"e9\"], [\"e8\", \"e7\"], [\"e8\", \"d8\"], [\"e8\", \"f8\"]]\n",
    "# adding to moves\n",
    "for from_pos, to_pos in [\n",
    "    *r_elephant,\n",
    "    *b_elephant,\n",
    "    *r_advisor,\n",
    "    *b_advisor,\n",
    "    *r_king,\n",
    "    *b_king,\n",
    "]:\n",
    "    moves.add(f\"{from_pos}{to_pos}\")\n",
    "    moves.add(f\"{to_pos}{from_pos}\")\n",
    "\n",
    "MOVE_ID = bidict({move: idx for idx, move in enumerate(moves)})\n",
    "\n",
    "print(MOVE_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32baccd",
   "metadata": {},
   "source": [
    "`encode_fen` takes a fen string representing the board position, and will make it into an array representing pieces using `PIECE_VAL`. `decode_fen` does the oppositte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e95e2c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_fen(fen: str) -> npt.NDArray[np.int_]:\n",
    "    board = np.zeros((10, 9), dtype=int)\n",
    "    rows = fen.split()[0].split(\"/\")\n",
    "    for i, row in enumerate(rows):\n",
    "        col = 0\n",
    "        for char in row:\n",
    "            if char.isdigit():\n",
    "                col += int(char)\n",
    "            else:\n",
    "                board[i, col] = PIECE_VAL[char]\n",
    "                col += 1\n",
    "    return board\n",
    "\n",
    "\n",
    "def decode_fen(fen_board: npt.NDArray[np.int_], turn: str) -> str:\n",
    "    fen_rows = []\n",
    "    for row in fen_board:\n",
    "        fen_row = \"\"\n",
    "        empty_count = 0\n",
    "        for piece in row:\n",
    "            if piece == 0:\n",
    "                empty_count += 1\n",
    "            else:\n",
    "                if empty_count > 0:\n",
    "                    fen_row += str(empty_count)\n",
    "                    empty_count = 0\n",
    "                fen_row += PIECE_VAL.inv[piece]\n",
    "        if empty_count > 0:\n",
    "            fen_row += str(empty_count)\n",
    "        fen_rows.append(fen_row)\n",
    "\n",
    "    fen = \"/\".join(fen_rows)\n",
    "    turn = \"w\" if turn[0].lower() == \"r\" or turn[0].lower() == \"w\" else \"b\"\n",
    "    return f\"{fen} {turn}\"\n",
    "\n",
    "\n",
    "# Test\n",
    "test_fen = \"rnbakabnr/9/1c5c1/p1p1p1p1p/9/9/P1P1P1P1P/1C5C1/9/RNBAKABNR w\"\n",
    "test_board = np.array(\n",
    "    [\n",
    "        [12, 11, 10, 9, 8, 9, 10, 11, 12],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 13, 0, 0, 0, 0, 0, 13, 0],\n",
    "        [14, 0, 14, 0, 14, 0, 14, 0, 14],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [7, 0, 7, 0, 7, 0, 7, 0, 7],\n",
    "        [0, 6, 0, 0, 0, 0, 0, 6, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [5, 4, 3, 2, 1, 2, 3, 4, 5],\n",
    "    ]\n",
    ")\n",
    "assert (encode_fen(test_fen) == test_board).all()\n",
    "assert decode_fen(test_board, \"red\") == test_fen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a331308e",
   "metadata": {},
   "source": [
    "`encode_move` uses the previously generated dictionary to encode the moves from the training data. `decode_move` does the oppositte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cff3e38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_move(move: str) -> npt.NDArray[np.int_]:\n",
    "    move_id = MOVE_ID[move]\n",
    "    one_hot_move = np.zeros(len(MOVE_ID), dtype=np.int_)\n",
    "    one_hot_move[move_id] = 1\n",
    "    return one_hot_move\n",
    "\n",
    "\n",
    "def decode_move(one_hot_move: npt.NDArray[np.float_]) -> str:\n",
    "    move_id = int(np.argmax(one_hot_move))\n",
    "    return MOVE_ID.inv[move_id]\n",
    "\n",
    "\n",
    "# Test\n",
    "test_move_id = np.argmax(encode_move(\"b2e2\"))\n",
    "test_one_hot_move = np.zeros(len(MOVE_ID), dtype=np.float_)\n",
    "test_one_hot_move[test_move_id] = 1\n",
    "assert (encode_move(\"b2e2\") == test_one_hot_move).all()\n",
    "assert decode_move(test_one_hot_move) == \"b2e2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1216f9e",
   "metadata": {},
   "source": [
    "`load_data` will read a file containing the best move of a position, the weight of the move, and the FEN string representing the current position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7efd223",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path: str) -> tuple[npt.NDArray[np.int_], npt.NDArray[np.int_]]:\n",
    "    fens: list[npt.NDArray[np.int_]] = []\n",
    "    best_moves: list[npt.NDArray[np.int_]] = []\n",
    "    with open(file_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            best_move, _, fen = line.strip().split(maxsplit=2)\n",
    "            fens.append(encode_fen(fen))\n",
    "            best_moves.append(encode_move(best_move))\n",
    "    return np.array(fens), np.array(best_moves)\n",
    "\n",
    "\n",
    "# Test\n",
    "test_fens, test_best_moves = load_data(DATA_PATH)\n",
    "assert (\n",
    "    test_fens[0]\n",
    "    == encode_fen(\n",
    "        \"rnbakabnr/9/1c5c1/p1p1p1p1p/9/9/P1P1P1P1P/1C5C1/9/RNBAKABNR w - - 0 1\"\n",
    "    )\n",
    ").all()\n",
    "assert (test_best_moves[0] == encode_move(\"b2e2\")).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c8ba46",
   "metadata": {},
   "source": [
    "We define the architecture of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c405569f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    inputs = tfk.Input(shape=BOARD_SIZE, dtype=tf.int32)\n",
    "\n",
    "    x = layers.Embedding(input_dim=len(PIECE_VAL) + 1, output_dim=16)(inputs)\n",
    "    x = layers.Reshape((*BOARD_SIZE, 8))(x)\n",
    "\n",
    "    x = layers.Conv2D(16, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(128, activation=\"relu\")(x)\n",
    "\n",
    "    outputs = layers.Dense(len(MOVE_ID), activation=\"softmax\")(x)\n",
    "\n",
    "    model = models.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2faa7b8b",
   "metadata": {},
   "source": [
    "Finally, we train and save our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c76e06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1738075680.771894   58867 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1718 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "2025-01-29 00:48:03.009342: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 344073184 exceeds 10% of free system memory.\n",
      "2025-01-29 00:48:03.786115: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 344073184 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 00:48:07.211673: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 344073184 exceeds 10% of free system memory.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1738075692.600778   59000 service.cc:148] XLA service 0x7e7820005ca0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1738075692.601277   59000 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce GTX 1050, Compute Capability 6.1\n",
      "2025-01-29 00:48:12.755376: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1738075693.617282   59000 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2025-01-29 00:48:14.433404: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{} for conv (f16[16,16,10,9]{3,2,1,0}, u8[0]{0}) custom-call(f16[16,8,10,9]{3,2,1,0}, f16[16,8,3,3]{3,2,1,0}, f16[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
      "2025-01-29 00:48:14.940769: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{} for conv (f16[16,32,10,9]{3,2,1,0}, u8[0]{0}) custom-call(f16[16,16,10,9]{3,2,1,0}, f16[32,16,3,3]{3,2,1,0}, f16[32]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
      "2025-01-29 00:48:15.114219: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{} for conv (f16[16,64,5,4]{3,2,1,0}, u8[0]{0}) custom-call(f16[16,32,5,4]{3,2,1,0}, f16[64,32,3,3]{3,2,1,0}, f16[64]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  12/1289\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: nan     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 00:48:21.133605: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_1', 4 bytes spill stores, 16 bytes spill loads\n",
      "\n",
      "I0000 00:00:1738075701.170924   59000 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1286/1289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.4177e-04 - loss: nan"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 00:48:33.665031: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{} for conv (f16[10,16,10,9]{3,2,1,0}, u8[0]{0}) custom-call(f16[10,8,10,9]{3,2,1,0}, f16[16,8,3,3]{3,2,1,0}, f16[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
      "2025-01-29 00:48:33.822785: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{} for conv (f16[10,32,10,9]{3,2,1,0}, u8[0]{0}) custom-call(f16[10,16,10,9]{3,2,1,0}, f16[32,16,3,3]{3,2,1,0}, f16[32]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
      "2025-01-29 00:48:33.993125: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{} for conv (f16[10,64,5,4]{3,2,1,0}, u8[0]{0}) custom-call(f16[10,32,5,4]{3,2,1,0}, f16[64,32,3,3]{3,2,1,0}, f16[64]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "\u001b[1m1289/1289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.4200e-04 - loss: nan"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 00:48:39.838818: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_1', 4 bytes spill stores, 16 bytes spill loads\n",
      "\n",
      "2025-01-29 00:48:39.940285: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 344073184 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1289/1289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 16ms/step - accuracy: 1.4208e-04 - loss: nan\n",
      "Epoch 2/10\n",
      "\u001b[1m  11/1289\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - loss: nan"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 00:48:41.503381: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2025-01-29 00:48:41.503503: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_2]]\n",
      "2025-01-29 00:48:41.503541: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 7311516728679555266\n",
      "2025-01-29 00:48:41.503622: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 5252902843587143082\n",
      "/home/le-moski/.local/lib/python3.10/site-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1289/1289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - accuracy: 1.4208e-04 - loss: nan\n",
      "Epoch 3/10\n",
      "\u001b[1m  11/1289\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - loss: nan"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 00:48:54.452721: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_2]]\n",
      "2025-01-29 00:48:54.452866: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 7311516728679555266\n",
      "2025-01-29 00:48:54.452956: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 5252902843587143082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1289/1289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - accuracy: 1.4208e-04 - loss: nan\n",
      "Epoch 4/10\n",
      "\u001b[1m  11/1289\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - loss: nan"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 00:49:09.126253: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 7311516728679555266\n",
      "2025-01-29 00:49:09.126361: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 5252902843587143082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1289/1289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - accuracy: 1.4208e-04 - loss: nan\n",
      "Epoch 5/10\n",
      "\u001b[1m  15/1289\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - loss: nan"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 00:49:23.818903: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_2]]\n",
      "2025-01-29 00:49:23.819016: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 7311516728679555266\n",
      "2025-01-29 00:49:23.819080: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 5252902843587143082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1289/1289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 11ms/step - accuracy: 1.4208e-04 - loss: nan\n",
      "Epoch 6/10\n",
      "\u001b[1m  19/1289\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 00:49:37.963293: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 7311516728679555266\n",
      "2025-01-29 00:49:37.963467: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 5252902843587143082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1289/1289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - accuracy: 1.4208e-04 - loss: nan\n",
      "Epoch 7/10\n",
      "\u001b[1m  24/1289\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 00:49:50.940810: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 7311516728679555266\n",
      "2025-01-29 00:49:50.940866: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 5252902843587143082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1289/1289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 20ms/step - accuracy: 1.4208e-04 - loss: nan\n",
      "Epoch 8/10\n",
      "\u001b[1m  20/1289\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 00:50:16.203918: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 7311516728679555266\n",
      "2025-01-29 00:50:16.204007: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 5252902843587143082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1289/1289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 15ms/step - accuracy: 1.4208e-04 - loss: nan\n",
      "Epoch 9/10\n",
      "\u001b[1m  18/1289\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: nan"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 00:50:35.370942: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_2]]\n",
      "2025-01-29 00:50:35.371024: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 7311516728679555266\n",
      "2025-01-29 00:50:35.371079: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 5252902843587143082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1289/1289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 1.4208e-04 - loss: nan\n",
      "Epoch 10/10\n",
      "\u001b[1m   7/1289\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: nan"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 00:50:47.576664: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 7311516728679555266\n",
      "2025-01-29 00:50:47.576798: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 5252902843587143082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1289/1289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 19ms/step - accuracy: 1.4208e-04 - loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 00:51:12.118826: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 7311516728679555266\n",
      "2025-01-29 00:51:12.118970: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 5252902843587143082\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "data = load_data(DATA_PATH)\n",
    "\n",
    "batch_size = 16\n",
    "dataset = (\n",
    "    tf.data.Dataset.from_tensor_slices(data)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
    ")\n",
    "dataset_size = len(data[0])\n",
    "train_size = int(0.8 * dataset_size)\n",
    "val_size = dataset_size - train_size\n",
    "\n",
    "train_dataset = dataset.take(train_size)\n",
    "val_dataset = dataset.skip(train_size)\n",
    "\n",
    "model = create_model()\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "model.fit(train_dataset, epochs=10, validation_data=val_dataset, verbose=1)\n",
    "\n",
    "model.save(\"xiangqi_model.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
PATH)\n\nbatch_size = 16\ndataset = (\n    tf.data.Dataset.from_tensor_slices(data)\n    .batch(batch_size)\n    .prefetch(tf.data.experimental.AUTOTUNE)\n)\ndataset_size = len(data[0])\ntrain_size = int(0.8 * dataset_size)\nval_size = dataset_size - train_size\n\ntrain_dataset = dataset.take(train_size)\nval_dataset = dataset.skip(train_size)\n\nmodel = create_model()\nmodel.compile(\n    optimizer=\"adam\",\n    loss=\"categorical_crossentropy\",\n    metrics=[\"accuracy\"],\n)\n\nmodel.fit(train_dataset, epochs=10, validation_data=val_dataset, verbose=1)\n\nmodel.save(\"xiangqi_model.keras\")"
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}